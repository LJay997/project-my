https://www.r2coding.com/#/README?id=%e9%9d%a2%e8%af%95%e9%a2%98%e9%9b%86%e5%90%88 [面试题集合](https://www.r2coding.com/#/README?id=面试题集合)

# MySQL面试硬核25问（附答案）https://mp.weixin.qq.com/s/vdOOVQtZhrJXsvRUjq0HqQ

# MYSQL

## innodb

### 表空间结构

- **系统表空间**：系统表空间是变更缓冲区的存储区域。包含数据字典、(8.0 版本修改了双写缓冲区)、插入缓冲索引页、系统事务信息等，默认包含undo回滚段。可以有一个或多个数据文件。默认情况下，在数据目录中创建一个名为`ibdata1`的单个系统表空间数据文件。
- **用户表空间**：当innodb_file_per_table=true时，一个表对应一个独立的文件，存储表的数据和索引。可以使用`DATA DIRECTORY`子句在[`CREATE TABLE`](https://dev.mysql.com/doc/refman/8.0/en/create-table.html)语句中隐式地在数据目录外部创建一个表对应一个文件的表空间数据文件。
- **redo log**：在崩溃恢复期间用于纠正由未完成事务写入的数据。在数据库正常运行的时候，只要有对表数据进行改变的请求，重做日志就会把这个请求以一种编码的方式记录下来。
- **临时表空间(Temporary Tablespaces)**：会话临时表空间和全局临时表空间,会话临时表空间存储**用户创建**的临时表以及当 InnoDB 被配置为磁盘内部临时表的存储引擎时，**优化器创建**的内部临时表。全局临时表空间（ibtmp1）存储对用户创建的临时表所做更改的回滚段。
- **undo独立表空间**：撤销表空间包含撤销日志，撤销日志是包含有关如何撤销事务对聚簇索引记录的最新更改的信息的记录集合。当 MySQL 实例初始化时，会创建两个默认的撤销表空间 文件名为``innodb_undo_001``和``innodb_undo_002``。因为在长时间运行的事务中，回滚日志可能会变得很大，创建额外的回滚表空间可以帮助防止单个回滚表空间变得过大。从 MySQL 8.0.14 开始，可以使用 CREATE UNDO TABLESPACE 语法在运行时创建额外的回滚表空间。
- **双写缓冲区**:是一个存储区域，在该区域中，InnoDB 在将从**缓冲池中刷新的页写入 InnoDB 数据文件中的适当位置之前**，先将这些页写入此处。如果在页写入过程中出现操作系统、存储子系统故障或意外的 mysqld 进程退出，InnoDB 可以在崩溃恢复期间从双写缓冲区中找到该页的良好副本。(在 MySQL 8.0.20 之前，双写缓冲区存储区域位于 InnoDB 系统表空间中。从 MySQL 8.0.20 开始，双写缓冲区存储区域位于双写文件中。)
  https://blog.csdn.net/javaJasonjava/article/details/144137878  InnoDB内存架构

### 索引结构

![InnoDB architecture diagram showing in-memory and on-disk structures. In-memory structures include the buffer pool, adaptive hash index, change buffer, and log buffer. On-disk structures include tablespaces, redo logs, and doublewrite buffer files.](https://p9-flow-imagex-sign.byteimg.com/tos-cn-i-a9rns2rl98/3ccd35b9ed294d39be8ddc55e3cba86f~tplv-a9rns2rl98-image-qvalue.jpeg?rk3s=4a10e4d4&x-expires=1739417683&x-signature=mQFDfDnneklZzLjAVF310I8xtk4%3D)

```sql
mysql> USE test;

mysql> CREATE TABLE t1 (
   id INT PRIMARY KEY AUTO_INCREMENT,
   name VARCHAR(100)
 ) ENGINE = InnoDB;

$> cd /path/to/mysql/data/test
$> ls
t1.ibd
```

- **B+树**：InnoDB使用B+树作为索引的数据结构，非叶子节点保存指向非叶子节点或叶子节点的指针，叶子节点保存真正的数据。
- **聚簇索引**：数据按照主键的顺序存储在叶子节点中，一个表只能有一个聚簇索引。
- **二级索引**：叶子节点存储的是索引列的值和主键值，通过主键值可以在聚簇索引中找到对应的行数据。

### 物理存储

- **页（Page）**：InnoDB的物理文件以页为单位进行存储，默认大小为16KB。
- **段（Segment）**：表空间管理的逻辑单位，每个B+树使用两个段来管理页，分别是叶子节点段和非叶子节点段。
- **区（Extent）**：由64个连续的页组成，用于高效的分配和管理页。

### 数据存储

- **数据页**：存储表中的行数据和索引数据。
- **索引页**：存储索引数据，包括索引列的值和指针。
- **系统数据页**：存储系统相关的数据，如事务信息、数据字典等。

### 内存结构

- **缓冲池（Buffer Pool）**：用于缓存数据页和索引页，提高数据的访问速度。
- **自适应哈希索引（Adaptive Hash Index）**：根据查询的频率和模式，自动在内存中构建哈希索引，提高查询效率。

### 相关数据结构

- **文件管理页（FSP_HDR/XDES）**：用于分配和管理区和页。
- **INODE页**：用于管理段的元信息。6
- **IBUF_BITMAP页**：用于跟踪每个页的change buffer信息。

### 注意事项

- 以上结构是基于MySQL 5.7及以上版本的InnoDB存储引擎，不同版本可能会有一些差异。
- 实际的物理结构可能会因为数据的插入、更新和删除而发生变化。

## InnoDB 锁定和事务模型

### Locking

- [Shared and Exclusive Locks 共享锁和排他锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-shared-exclusive-locks)
- [Intention Locks 意向锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-intention-locks)
- [Record Locks “记录锁”。](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-record-locks)
- [Gap Locks 间隙锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-gap-locks)
- [Next-Key Locks Next-Key Locks（下一键锁）。](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-next-key-locks)
- [Insert Intention Locks 插入意向锁](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-insert-intention-locks)
- [AUTO-INC Locks “AUTO-INC 锁”。](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-auto-inc-locks)
- [Predicate Locks for Spatial Indexes 谓词锁用于空间索引](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-predicate-locks)

MySQL 通过事务隔离级别和锁机制来解决“不可重复读”和“幻读”问题，具体如下：

---

### 一、不可重复读的解决方式

**问题回顾**：一个事务内多次读取同一数据，由于其他事务修改并提交了该数据，导致前后读取结果不一致。

**解决方法**：

1. **设置事务隔离级别为 Repeatable Read（可重复读）**
    - 这是 MySQL InnoDB 默认的隔离级别。
    - 在该级别下，事务执行过程中看到的数据与事务启动时一致，避免了不可重复读。

2. **使用锁机制**
    - 读取数据时加**共享锁**（S锁），写数据时加**排他锁**（X锁）。
    - 锁在事务提交后才释放，确保事务期间数据不被其他事务修改。

---

### 二、幻读的解决方式

**问题回顾**：一个事务在两次查询某范围数据时，因其他事务插入新数据，导致结果集出现“幻影行”。

**解决方法**：

1. **设置事务隔离级别为 Serializable（串行化）**
    - 最高级别，完全避免幻读，但性能差，实际中很少使用。

2. **MySQL InnoDB 的默认隔离级别（Repeatable Read）也能很大程度避免幻读**，具体靠两种机制：
    - **快照读（普通 SELECT）**：通过 **MVCC（多版本并发控制）** 实现。事务读取的是启动时的数据快照，其他事务插入的新数据不会被看到。
    - **当前读（SELECT ... FOR UPDATE / SELECT ... LOCK IN SHARE MODE）**：通过 **Next-Key Lock（记录锁 + 间隙锁）** 实现。它会锁定查询范围，防止其他事务插入新数据，从而避免幻读。

---

### 三、总结

| 问题类型     | 解决方式                          | 核心机制             |
|--------------|-----------------------------------|----------------------|
| 不可重复读   | 设置隔离级别为 Repeatable Read    | MVCC + 锁机制        |
| 幻读         | 设置隔离级别为 Serializable       | 串行化执行           |
| 幻读（优化） | 默认隔离级别 Repeatable Read      | MVCC（快照读）+ Next-Key Lock（当前读） |

通过合理选择隔离级别和锁机制，MySQL 能有效避免不可重复读和幻读问题，兼顾数据一致性和性能。


#### Shared and Exclusive Locks 共享锁和排他锁

共享（S）锁:允许持有该锁的事务**读取**一行

和排他（X）锁:允许持有该锁的事务**更新或删除**一行

> 如果事务`T1`对行`r`持有共享(`S`)锁，那么来自某个不同事务`T2`对行`r`的锁请求将按如下方式处理：
>
> - `T2` 请求`S`锁可以立即被批准。结果，`T1`和`T2`都在`r`上持有`S`锁。
> - `T2`请求`X`锁不能立即被批准。
>
> 如果事务 `T1` 对行 `r` 持有排他（`X`）锁，那么来自某个不同事务 `T2` 对行 `r` 的任何类型锁的请求都不能立即被授予。相反，事务 `T2` 必须等待事务 `T1` 释放其在行 `r` 上的锁。

#### Intention Locks 意图锁

意向锁是表级锁，表明事务稍后对于表中的一行需要哪种类型的锁

- 一个“意向共享锁”（IS）表示一个事务打算在**表中的各个行上**设置一个“共享”锁。
- 一个“意向排他锁”（“intention exclusive lock”，缩写为“IX”）表示一个事务打算在**表中的各个行上**设置排他锁。

---

[MySQL记录锁、间隙锁、临键锁](https://www.cnblogs.com/LoveShare/p/17023767.html)
包含了以上的大部分内容
----------------------

## **一、SQL 优化的核心方向**

### 1. **索引优化**

- **B+树原理**：索引的底层数据结构，范围查询高效。
- **最左前缀原则**：联合索引的顺序对查询的影响。
- **覆盖索引**：直接从索引中获取数据，避免回表。
- **索引失效场景**：
    - 对字段进行运算（如 `WHERE YEAR(create_time) = 2023`）。
    - 使用前导通配符（如 `LIKE '%abc'`）。
    - 隐式类型转换（如字符串字段用数字查询）。

### 2. **查询语句优化**

- **避免 `SELECT ***`：明确指定所需字段，减少数据传输。
- **使用 `EXISTS` 替代 `IN`**：当子查询结果集较大时，`EXISTS` 效率更高。
- **分页优化**：避免 `OFFSET` 过大，改用 `WHERE id > last_id LIMIT n`。
- **减少 `JOIN` 的复杂度**：小表驱动大表，避免笛卡尔积。

### 3. **表结构优化**

- **选择合适的数据类型**：如用 `INT` 替代 `VARCHAR` 存储数字。
- **避免过度范式化**：适当冗余高频访问字段。
- **分区表**：按时间或范围拆分大表（如按月分表）。

### 4. **执行计划分析**

- **`EXPLAIN` 关键字段**：
    - `type`：`const` > `ref` > `range` > `index` > `ALL`。
    - `rows`：预估扫描行数，越小越好。
    - `Extra`：`Using index`（覆盖索引）、`Using temporary`（临时表）等。

---

## **二、高频 SQL 优化场景与实战**

### 场景 1：**慢查询优化**

- **问题**：`SELECT * FROM orders WHERE user_id=100 ORDER BY create_time DESC LIMIT 1000,10;`（`user_id` 无索引）。
- **优化**：为 `user_id` 和 `create_time` 添加联合索引。

### 场景 2：**大数据量插入**

- **问题**：单条 `INSERT` 插入 10 万条数据速度慢。
- **优化**：使用批量插入（`INSERT INTO ... VALUES (...), (...), ...`），或 `LOAD DATA INFILE`。

### 场景 3：**死锁分析**

- **问题**：事务 A 先更新 `id=1`，再更新 `id=2`；事务 B 先更新 `id=2`，再更新 `id=1`。
- **解决**：保证事务中操作顺序一致。

---

## **三、经典 SQL 优化面试题**

### **概念题**

1. **索引为什么用 B+ 树而不是哈希表？**
   **答**：哈希表无法高效支持范围查询和排序，B+ 树的叶子节点链表结构适合范围扫描。
2. **什么是回表查询？如何避免？**
   **答**：回表是指通过二级索引找到主键后，再通过聚簇索引查数据。使用覆盖索引（索引包含查询字段）可避免。
3. **`UNION` 和 `UNION ALL` 的区别？优化时如何选择？**
   **答**：`UNION` 去重且排序，效率低；`UNION ALL` 直接合并结果集，优先使用。

---

### **实战题**

1. **优化以下查询**：

   ```sql
   SELECT * FROM users 
   WHERE age > 20 
   ORDER BY name 
   LIMIT 100000, 10;
   ```

   **优化方案**：

    - 添加联合索引 `(age, name)`，改写为：

      ```sql
      SELECT * FROM users 
      WHERE id >= (SELECT id FROM users WHERE age > 20 ORDER BY name LIMIT 100000, 1) 
      LIMIT 10;
      ```
2. **分析执行计划中的 `Using filesort` 如何解决？**
   **答**：`ORDER BY` 的字段未命中索引，需添加联合索引（如 `WHERE` 条件字段 + `ORDER BY` 字段）。

---

## **四、推荐学习资料**

### 1. **书籍**

- **《高性能 MySQL》**：第 5 章（索引）、第 6 章（查询优化）。
- **《数据库索引设计与优化》**：深入讲解索引设计原理。

### 2. **在线文档**

- **MySQL 官方文档**：[Optimization and Indexes](https://dev.mysql.com/doc/refman/8.0/en/optimization-indexes.html)。
- **PostgreSQL 执行计划解读**：[EXPLAIN 使用指南](https://www.postgresql.org/docs/current/using-explain.html)。

### 3. **实战工具**

- **Percona Toolkit**：`pt-query-digest` 分析慢查询日志。
- **SQL 可视化工具**：Navicat、DBeaver 的执行计划分析功能。

---

## **五、高级优化技巧**

1. **读写分离**：主库处理写操作，从库处理读操作。
2. **分库分表**：按业务拆分数据库（如用户库、订单库）。
3. **缓存策略**：使用 Redis 缓存热点查询结果。
4. **异步处理**：非实时任务走消息队列（如 RabbitMQ）。

优化和索引
----------

[10.3.1 MySQL 如何使用索引](https://dev.mysql.com/doc/refman/8.0/en/mysql-indexes.html)

[10.3.2 主键优化](https://dev.mysql.com/doc/refman/8.0/en/primary-key-optimization.html)

[10.3.3 SPATIAL 索引优化](https://dev.mysql.com/doc/refman/8.0/en/spatial-index-optimization.html)

[10.3.4 外键优化](https://dev.mysql.com/doc/refman/8.0/en/foreign-key-optimization.html)

[10.3.5 列索引](https://dev.mysql.com/doc/refman/8.0/en/column-indexes.html)

[10.3.6 多列索引](https://dev.mysql.com/doc/refman/8.0/en/multiple-column-indexes.html)

[10.3.7 验证索引使用情况](https://dev.mysql.com/doc/refman/8.0/en/verifying-index-usage.html)

[10.3.8 InnoDB 和 MyISAM 索引统计信息收集](https://dev.mysql.com/doc/refman/8.0/en/index-statistics.html)

[10.3.9 B 树索引和哈希索引的比较](https://dev.mysql.com/doc/refman/8.0/en/index-btree-hash.html)

[10.3.10 索引扩展的使用](https://dev.mysql.com/doc/refman/8.0/en/index-extensions.html)

[10.3.11 优化器对生成的列索引的使用](https://dev.mysql.com/doc/refman/8.0/en/generated-column-index-optimizations.html)

[10.3.12 不可见索引](https://dev.mysql.com/doc/refman/8.0/en/invisible-indexes.html)

[10.3.13 降序索引](https://dev.mysql.com/doc/refman/8.0/en/descending-indexes.html)

[10.3.14 来自 TIMESTAMP 列的索引查找](https://dev.mysql.com/doc/refman/8.0/en/timestamp-lookups.html)

#### 使用索引

大多数 MySQL 索引<u>（“PRIMARY KEY”、“UNIQUE”、“INDEX”和“FULLTEXT”）</u>存储在“B 树”中 “InnoDB”对“<u>FULLTEXT</u>”索引使用倒排链表。

如果表有一个**多列索引**，索引的任何<u>最左前缀都可以被优化器用来查找行</u>。例如，如果您在(col1, col2, col3)上有一个三列索引，那么您可以在(col1)、(col1, col2)和(col1, col2, col3)上使用索引搜索功能。

如果对表进行排序或分组是在可用索引的**最左侧前缀**上进行的.
Index Prefixes 索引前缀

在字符串列的索引规范中使用 `col_name(N)` 语法，可以创建仅使用该列的前*`N`* 个字符的索引。以这种方式仅对列值的前缀进行索引可以使索引文件小得多。当您为[`BLOB`](https://dev.mysql.com/doc/refman/8.0/en/blob.html "13.3.4 The BLOB and TEXT Types") 或[`TEXT`](https://dev.mysql.com/doc/refman/8.0/en/blob.html "13.3.4 The BLOB and TEXT Types") 列编制索引时，*必须*为 index 指定前缀长度。

```sql
CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10)));
```

#### 多列索引

```sql
CREATE TABLE test (
    id         INT NOT NULL,
    last_name  CHAR(30) NOT NULL,
    first_name CHAR(30) NOT NULL,
    PRIMARY KEY (id),
    INDEX name (last_name,first_name)
);
```

作为组合索引的替代方法，您可以引入基于其他列的信息进行“哈希”处理的列。

```sql
SELECT * FROM tbl_name WHERE hash_col=MD5(CONCAT(val1,val2)) AND col1=val1 AND col2=val2;
```

使用 EXPLAIN 语句,检查查询是否确实使用在表中创建的索引

#### B 树索引特征

B 树索引可用于使用 =、>、>=、<、<= 或 BETWEEN 运算符的列比较表达式。如果LIKE 的参数是不以通配符开头的常量字符串，则 index也可用于 LIKE比较。

```sql
SELECT * FROM tbl_name WHERE key_col LIKE 'Patrick%';
SELECT * FROM tbl_name WHERE key_col LIKE 'Pat%_ck%';

-- 以下不使用索引 在第一个语句中，LIKE值以通配符开头。在第二个语句中，LIKE 值不是常量。
SELECT * FROM tbl_name WHERE key_col LIKE '%Patrick%';
SELECT * FROM tbl_name WHERE key_col LIKE other_col;
```

#### 哈希索引特性

* 它们仅用于使用“=”或“<=>”运算符的相等比较,不能用于范围查询.
* 不能加速`ORDER BY`操作.

#### 使用索引扩展

`InnoDB`会自动扩展每个二级索引，方法是将主键列附加到索引上。

```sql
CREATE TABLE t1 (
    i1 INT NOT NULL DEFAULT 0,
    i2 INT NOT NULL DEFAULT 0,
    d DATE DEFAULT NULL,
    PRIMARY KEY (i1, i2),
    INDEX k_d (d)
) ENGINE = InnoDB;
```

内部`InnoDB`扩展了此索引并将其视为列`(d, i1, i2)`
优化器可以将扩展二级索引用于**ref、range以及index_merge**索引访问、用于松散索引扫描访问、用于连接和排序优化以及用于MIN()/MAX()优化。

状态检查 [SHOW STATUS](https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html#statvar_Handler_read_next)

```sql
FLUSH TABLE t1;
FLUSH STATUS;
SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = '2000-01-01';
SHOW STATUS LIKE 'handler_read%'
```

使用[SHOW WARNINGS](https://dev.mysql.com/doc/refman/8.0/en/show-warnings.html)查看优化后的查询语句
“SHOW WARNINGS也在EXPLAIN之后使用，以显示由EXPLAIN生成的扩展信息。

#### 使用 EXPLAIN 优化查询

对于SELECT语句，EXPLAIN会生成额外的执行计划信息，这些信息可以使用**SHOW WARNINGS**显示。

### 基本概念

- **EXPLAIN命令的作用是什么？**
- EXPLAIN命令用于分析查询语句的执行计划，帮助了解MySQL如何处理查询，包括表的读取顺序、数据读取操作的类型、使用的索引等信息，从而找出查询性能瓶颈并进行优化。
- **EXPLAIN命令的输出结果有哪些列？**
- EXPLAIN命令输出结果包含id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra等列。

### 字段含义

- **id列的作用是什么？**
- id列表示查询中执行SELECT子句或操作表的顺序。如果id相同，执行顺序由上至下；如果id不同，id的序号会递增，id值越大优先级越高，越先被执行。
- **select_type列有哪些常见类型？**
- 常见的select_type类型有SIMPLE（简单查询）、PRIMARY（包含UNION或子查询时最外层的查询）、UNION（UNION中的第二个或随后的查询）、SUBQUERY（子查询中的第一个select语句）等。
- **type列有哪些常见取值？**
- system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
- 常见的type取值有ALL（全表扫描，性能最差）、index（全索引扫描）、range（范围扫描）、ref（索引查找）、eq_ref（使用唯一性索引或主键查找，非常高效）、const、system（表至多有一个匹配行或系统表）、NULL（执行阶段不需要访问表）。
- **possible_keys和key列的区别是什么？**
- possible_keys列显示查询可能使用哪些索引来查找，而key列显示MySQL实际决定使用的索引。
- **key_len列的含义是什么？**
- key_len列显示了在索引里使用的字节数，可用于判断索引使用情况。
- **ref列的作用是什么？**
- ref列显示了哪些字段或者常量被用来和key配合从表中查询记录出来。
- **rows列的含义是什么？**
- rows列显示了估计要找到所需的行而要读取的行数，原则上值越小越好。
- **Extra列常见的取值有哪些？**
- 常见的Extra列取值有Using index（使用覆盖索引）、Using Where（在存储引擎检索行后再进行过滤）、Using temporary（查询结果排序时使用临时表）、Using filesort（对结果使用外部索引排序）等。

## 缓存和数据库一致性问题

订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 **canal**，使用这种方案的优点在于：
推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。
好的，我现在需要解决用户关于Java中缓存和数据库一致性问题的提问。首先，我得回顾一下用户提供的搜索结果，看看有哪些解决方案被提到，然后整理出有效的解决策略。

用户给的搜索结果里提到了几种方法，比如延迟双删结合MQ、Canal监听Binlog、使用分布式锁，以及先更新数据库再删除缓存的策略。我需要把这些方法分门别类，解释清楚每种方法的原理和适用场景。

首先，延迟双删加上消息队列。这个方法的思路是先删除缓存，然后更新数据库，之后再次延迟删除缓存。这样做是为了防止在更新数据库的过程中，有其他请求把旧数据重新加载到缓存。延迟的时间需要根据业务情况设定，不过这个时间可能难以准确估计，所以可能会存在短暂的不一致。不过结合MQ的重试机制，可以提高最终一致性。

然后，Canal监听MySQL的Binlog。这种方法通过中间件监听数据库的变更日志，一旦有数据更新，就将变更事件发送到消息队列，再由消费者更新缓存。这种方法解耦了业务代码和缓存更新逻辑，适合高并发场景，但需要维护Canal和消息队列，增加了系统复杂性。

接下来是分布式锁的方案。在读写操作时使用分布式锁，确保同一时间只有一个线程操作数据库和缓存。比如查询时，如果缓存失效，获取锁后查询数据库并更新缓存，其他线程等待锁释放后直接从缓存读取。更新时，先获取锁再更新数据库和删除缓存，避免并发写导致的数据混乱。这种方法能有效保证强一致性，但可能影响性能，尤其是在高并发下锁竞争激烈的情况。

还有一种常见的策略是先更新数据库再删除缓存（Cache-Aside Pattern）。虽然存在极低概率的脏数据问题，但通过设置合理的缓存过期时间和重试机制，可以极大降低不一致的窗口期。如果删除缓存失败，可以通过异步重试或消息队列确保最终删除。

另外，补偿机制如定时任务扫描或MQ消息重试，能够处理因网络问题导致的缓存更新失败，确保最终一致性。比如在更新数据库后发送消息到MQ，消费者负责删除缓存，失败则重试。

在总结这些方案时，需要注意它们的优缺点和适用场景。比如对于强一致性要求高的场景，分布式锁可能更合适；而对于高并发但允许短暂不一致的，Canal监听结合MQ可能更好。同时，要提到实际应用中可能需要多种方案结合，比如补偿机制和延迟双删一起使用，来提高可靠性。

还要考虑用户可能的疑问，比如如何选择延迟时间，如何处理极端情况下的不一致，以及系统复杂度与一致性的权衡。这时候需要给出建议，比如根据业务容忍度选择策略，或者使用成熟的中间件来降低实现难度。

最后，确保回答结构清晰，分点说明，每种方案都简明扼要地解释原理和步骤，并指出适用场景，让用户能根据自身情况做出选择。同时避免使用技术术语过多，保持语言通俗易懂，帮助用户理解不同解决方案的适用性。

在Java应用中解决缓存与数据库一致性问题，需根据业务场景选择不同策略。以下是常见解决方案及适用场景分析：

### 一、强一致性方案

**1. 分布式锁 + 双检机制**

- **原理**：在读写操作前后加分布式锁，确保同一时刻只有一个线程操作关键数据。
- **实现步骤**：
    - **查询**：先查缓存，若未命中则加锁查数据库→更新缓存→释放锁。
    - **更新**：加锁→更新数据库→删除缓存→释放锁。
- **适用场景**：对一致性要求极高（如金融交易），但并发性能会受锁竞争影响。

**2. 事务消息 + 延迟双删**

- **原理**：通过MQ事务消息确保数据库与缓存操作的原子性。
- **实现步骤**：
    1. 删除旧缓存
    2. 提交数据库事务
    3. 发送延迟MQ消息（如500ms）
    4. 消费消息再次删除缓存
- **优势**：兼顾性能与最终一致性，典型应用如电商库存扣减。

### 二、最终一致性方案

**1. Canal监听Binlog**

- **实现流程**：
    1. 开启MySQL的Binlog
    2. Canal解析Binlog并发送变更事件到Kafka
    3. 消费者监听Kafka消息更新Redis
- **优点**：完全解耦业务代码，适合高并发场景。
- **示例代码**：

```java
// Canal客户端监听示例
CanalConnector connector = CanalConnectors.newClusterConnector(
    "127.0.0.1:2181", "example", "", "");
connector.connect();
connector.subscribe(".*\\..*");
while (true) {
    Message message = connector.getWithoutAck(100);
    // 解析message并更新Redis
}
```

**2. 补偿机制**

- **定时任务补偿**：定期扫描数据库与缓存差异数据
- **MQ重试机制**：更新数据库后发送消息，消费者删除缓存失败时重试

```java
// RocketMQ生产者示例
public void updateDBAndSendMsg(Order order) {
    updateOrder(order); // 更新数据库
    Message msg = new Message("CACHE_TOPIC", 
        ("DELETE:" + order.getId()).getBytes());
    rocketMQTemplate.send(msg);
}
```

### 三、经典设计模式

**Cache-Aside Pattern**

1. **读流程**：
    - 先查缓存→命中则返回
    - 未命中则查数据库→写入缓存
2. **写流程**：
    - 先更新数据库→再删除缓存

- **注意点**：需处理缓存穿透（布隆过滤器）、雪崩（随机过期时间）问题

### 四、方案选型建议


| 方案        | 一致性强度 | 性能影响 | 实现复杂度 | 适用场景     |
| ----------- | ---------- | -------- | ---------- | ------------ |
| 分布式锁    | 强一致性   | 高       | 高         | 金融核心系统 |
| Canal监听   | 最终一致   | 低       | 中         | 高并发读场景 |
| 延迟双删+MQ | 最终一致   | 中       | 中         | 订单类业务   |
| 定时补偿    | 最终一致   | 低       | 低         | 低频更新业务 |

### 五、特殊场景处理

1. **热点数据更新**：结合版本号或时间戳，如：

```redis
SET order:1234 '{"v": 2, "data": {...}}'
```

2. **批量更新场景**：采用Redis管道批量删除

```java
try (Pipeline pipeline = jedis.pipelined()) {
    keys.forEach(pipeline::del);
    pipeline.sync();
}
```

## String 面试题目

### **一、String 基础面试题**

#### **1. String 是不可变类吗？为什么设计为不可变？**

**答：**

- **不可变性**：String 的 `value` 字段是 `private final char[]`（JDK 8）或 `byte[]`（JDK 9+），且没有修改该数组的方法。
- **设计原因**：
    1. **安全性**：防止敏感数据被篡改（如数据库连接字符串）。
    2. **哈希缓存**：String 常用于 HashMap 的 Key，不可变性保证哈希值稳定。
    3. **线程安全**：无需同步即可多线程共享。
    4. **常量池优化**：字符串字面量可被复用。

#### **2. `String s = new String("abc")` 创建了几个对象？**

**答：**

- **若常量池无 "abc"**：创建 2 个对象（堆中的 `String` 对象 + 常量池中的 "abc"）。
- **若常量池已有 "abc"**：创建 1 个对象（堆中的新 `String` 对象）。

---

### **二、`intern()` 方法核心原理**

#### **1. `intern()` 的作用是什么？**

**答：**将字符串对象的引用添加到字符串常量池（如果池中无等价字符串），并返回池中的引用。**JDK 版本差异**：

- **JDK 6**：常量池在永久代，`intern()` 会复制字符串到池中。
- **JDK 7+**：常量池在堆中，`intern()` 直接记录堆中字符串的引用。

#### **2. 代码分析：`intern()` 的经典案例**

```java
String s1 = new String("a") + new String("b");
s1.intern();
String s2 = "ab";
System.out.println(s1 == s2); // JDK7+：true
```

**解释**：

- `s1` 指向堆中的 "ab"。
- `s1.intern()` 将 "ab" 的引用存入常量池。
- `s2 = "ab"` 直接复用常量池的引用，故 `s1 == s2` 为 `true`。

---

### **三、高频进阶面试题**

#### **1. 字符串拼接的底层实现？**

**答**：

```java
String s = "a" + "b"; // 编译优化为 "ab"（常量折叠）
String s2 = s1 + "c"; // 转换为 new StringBuilder().append(s1).append("c").toString()
```

- **性能提示**：循环中避免使用 `+`，改用 `StringBuilder`。

#### **2. `String`、`StringBuilder`、`StringBuffer` 的区别？**


| 类              | 可变性 | 线程安全     | 性能 |
| --------------- | ------ | ------------ | ---- |
| `String`        | 不可变 | 安全         | 最低 |
| `StringBuilder` | 可变   | 不安全       | 最高 |
| `StringBuffer`  | 可变   | 安全（同步） | 中等 |

#### **3. `==` 与 `equals()` 的区别？**

- **`==`**：比较对象内存地址。
- **`equals()`**：比较字符串内容（String 已重写）。


### **Java中的参数传递机制是值传递。**

#### 基本数据类型的参数传递
- 当传递基本数据类型（如int、double、char等）时，传递的是该数据值的副本。
- 在方法内部对形参的修改不会影响到实参的值。

#### 引用数据类型的参数传递
- 当传递引用数据类型（如数组、类的对象等）时，传递的是对象的引用（内存地址）的副本。
- 在方法内部对形参所引用的对象的属性进行修改会影响到实参所引用的对象。
- 但是，如果在方法内部重新赋值形参，使其指向一个新的对象，那么这个操作不会影响到实参的引用。

#### 特殊情况
- **String类型**：虽然String是引用类型，但由于其不可变性，对String对象的操作实际上是创建了新的String对象，因此在方法内部对String形参的修改不会影响到实参。
- **包装类**：如Integer、Double等，它们是不可变的，与String类似，在方法内部对其形参的修改不会影响到实参。

#### 总结
- Java中的参数传递机制是值传递，无论是基本数据类型还是引用数据类型，传递的都是值的副本。
- 对于引用数据类型，虽然传递的是引用的副本，但通过该引用对对象属性的修改会影响到实参所引用的对象。

---

### **四、实战代码分析**

#### **案例 1：`intern()` 节省内存**

```java
String s1 = new String("Hello").intern(); // 指向常量池
String s2 = "Hello";
System.out.println(s1 == s2); // true
```

**优化场景**：处理大量重复字符串时，使用 `intern()` 减少堆内存占用。

#### **案例 2：JDK 版本差异**

```java
String s3 = new String("1") + new String("1");
s3.intern();
String s4 = "11";
System.out.println(s3 == s4); // JDK6：false；JDK7+：true
```

**解释**：JDK7+ 的常量池引用堆中对象，JDK6 的常量池在永久代，需复制。

---

### **五、总结**

- **核心考点**：不可变性、常量池、`intern()`、字符串拼接优化。
- **JDK 版本差异**：常量池位置影响 `intern()` 行为。
- **性能优化**：高频字符串操作优先用 `StringBuilder`，谨慎使用 `intern()` 避免内存溢出。
- **byte的取值范围是多少，怎么计算出来的**

`byte 的取值范围是 -128 -> 127 之间，一共是 256 。一个 byte 类型在计算机中占据一个字节，那么就是 8 bit，所以最大就是 2^7 = 1111 1111。Java 中用补码来表示二进制数，补码的最高位是符号位，最高位用 0 表示正数，最高位 1 表示负数，正数的补码就是其本身，由于最高位是符号位，所以正数表示的就是 0111 1111 ，也就是 127。最大负数就是 1111 1111，这其中会涉及到两个 0 ，一个 +0 ，一个 -0 ，+0 归为正数，也就是 0 ，-0 归为负数，也就是 -128，所以 byte 的范围就是 -128 - 127。`

一、补码的核心原理  补码定义：

- 正数：补码 = 原码
- 负数：补码 = 原码取反（符号位不变） + 1
- 0：所有位为0（唯一表示）
- 计算 -5 的补码
- 原码 1000 0101(符号位为1，数值部分为5)
- 补码 1111 1010(符号位不变，数值部分取反)
- 反码 1111 1011(反码是在补码的位置上加一)
- 计算 7 的 补码
- 原码 0000 0111(符号位为0，数值部分为7)
- 补码 0000 0111(符号位不变，数值部分不变)

https://javaguide.cn/java/basis/java-basic-questions-03.html

### 动态代理

https://javaguide.cn/java/basis/proxy.html#_3-2-cglib-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%9C%BA%E5%88%B6
Java 动态代理请看 java.lang.reflect.Proxy
cglib 动态代理请看 net.sf.cglib.proxy.Enhancer

## Java SPI 机制

`ServiceLoader`

## Dubbo SPI 机制

`ExtentionLoader`

https://javaguide.cn/java/basis/java-basic-questions-03.html#i-o

如何解决大文件上传问题

## JVM JMM

- **PC计数器**

  CPU需要不停的**切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行**。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。
- **Java 虚拟机栈**

  方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。

  栈由一个个栈帧组成，而每个栈帧中都拥有：_局部变量表(基本数据类型以及对象的引用)、操作数栈(中间变量和临时结果)、动态链接(找方法用的)、方法返回地址_。和数据结构上的栈类似，两者都是先进后出的数据结构，只支持出栈和入栈两种操作。
- 类加载器

---

### 1. **Callable 到 Runnable 的封装**

- **FutureTask 的作用**：
  `Callable` 本身是独立接口，但线程池的 `execute(Runnable)` 方法只能接受 `Runnable` 参数。因此，`Callable` 会被包装成 `FutureTask`（实现了 `RunnableFuture`，而 `RunnableFuture` 是 `Runnable` 和 `Future` 的组合）。
  ```java
  Callable<Integer> callable = ...;
  FutureTask<Integer> futureTask = new FutureTask<>(callable);
  executor.execute(futureTask);  // 此时提交的是 Runnable 类型
  ```

---

### 2. **执行结果的存储**

- **FutureTask 的 run() 方法**：
  当线程执行 `FutureTask.run()` 时，会调用 `Callable.call()` 方法，并将结果保存到 `FutureTask` 的内部变量 `outcome` 中：
  ```java
  public void run() {
      try {
          Callable<V> c = callable;
          if (c != null && state == NEW) {
              V result = c.call();  // 执行 Callable 的 call() 方法
              set(result);          // 将结果保存到 outcome
          }
      } catch (Throwable ex) {
          setException(ex);
      }
  }
  ```

---

### 3. **结果的获取（Future.get()）**

- **阻塞与状态检查**：当调用 `Future.get()` 时，如果任务未完成，当前线程会被阻塞（通过 `LockSupport.park()` 实现），直到任务完成。此时：
    - 如果任务成功执行，返回 `outcome`；
    - 如果任务抛出异常，抛出 `ExecutionException`。

  ```java
  public V get() throws InterruptedException, ExecutionException {
      int s = state;
      if (s <= COMPLETING)
          s = awaitDone(false, 0L);  // 阻塞直到任务完成
      return report(s);               // 返回结果或抛出异常
  }
  ```

1. CPU 密集型任务
   公式：线程池大小 = CPU 核心数 + 1
   解释：对于 CPU 密集型任务（如复杂的计算、加密等），线程数量应接近 CPU 核心数。额外的一个线程可以处理可能出现的 I/O 等待或其他阻塞操作。
2. I/O 密集型任务
   公式：线程池大小 = CPU 核心数 × (1 + 等待时间/服务时间)
   解释：对于 I/O 密集型任务（如网络请求、文件读写等），由于大部分时间线程都在等待 I/O 操作完成，因此可以增加线程数量以提高并发度。通常情况下，线程池大小可以设置为 CPU 核心数的几倍。

---

### 4. **关键设计点**

- **状态机（state）**：
  `FutureTask` 使用一个 `volatile` 变量 `state` 表示任务状态（如 `NEW`、`COMPLETING`、`NORMAL`、`CANCELLED` 等），通过状态判断是否需要阻塞或返回结果。
- **线程间通信**：
  内部通过 `LockSupport` 和 `WaitNode` 队列管理等待线程，确保 `get()` 的阻塞和唤醒机制高效可靠。

---

### 总结流程

```
Callable → 封装为 FutureTask（Runnable） → 提交到线程池 → 
执行 run() → 保存结果到 outcome → 通过 Future.get() 获取结果
```

**核心本质**：`FutureTask` 作为适配器，既实现了 `Runnable` 以适配线程池，又通过 `Future` 接口管理结果的存储和异步获取。

## Java 设计模式

### 观察者模式 Observable 和 Observer

https://javaguide.cn/java/concurrent/java-concurrent-questions-01.html#%E2%AD%90%EF%B8%8F%E8%AF%B7%E7%AE%80%E8%A6%81%E6%8F%8F%E8%BF%B0%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%85%B3%E7%B3%BB-%E5%8C%BA%E5%88%AB%E5%8F%8A%E4%BC%98%E7%BC%BA%E7%82%B9
TODO 看看Java 并发题

## JUC

Java 的 `Callable` 虽然被封装成了 `Runnable`（通过 `FutureTask` 实现），但其执行结果的获取是通过 **异步回调机制** 和 **状态管理** 实现的。具体流程如下：
ThreadLoacl 的使用

重点记忆 [260] 第22讲：ynchronized 和 Lock 孰优孰劣，如何选择？

## RocketMQ

思考，消息发送出去有没有返回值。如何确定发送后消息是否被消费了
RocketMQ 如何实现分布式事务？
https://javaguide.cn/high-performance/message-queue/rocketmq-questions.html#%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9

## DUBBO

## SpringBoot 加载机制

## Redis

https://mp.weixin.qq.com/s/RViDM1WHE61SDLNKzUmTAg

## Redisson

### BloomFilter 过滤器

**Redisson 布隆过滤器**初始化后‌不可动态调整‌ m 和 k，需提前预留冗余量（如按预估量的 120% 设定 n）‌67。

‌性能与内存权衡‌

低误判率场景（如金融风控）：优先保证准确性，接受更高内存开销。
高吞吐量场景（如 URL 去重）：适当放宽误判率以降低内存占用 。


```java
@Test
    public void testUseBloomFilter() {
        // 1. 初始化 Redisson 客户端连接
        RedissonClient redisson = Redisson.create();  // 需配置Redis地址、密码等

// 2. 获取或创建布隆过滤器实例
        RBloomFilter<String> usernameFilter = redisson.getBloomFilter("usernameFilter");

// 3. 初始化布隆过滤器参数（预期数据量、误判率）
        boolean isInitialized = usernameFilter.tryInit(1000000, 0.01);
        if (!isInitialized) {
            throw new RuntimeException("BloomFilter 初始化失败");
        }

// 4. 模拟数据预热（从数据库加载现有用户名到布隆过滤器）
        List<String> existingNames = database.query("SELECT username FROM users");
        for (String name : existingNames) {
            usernameFilter.add(name);  // 将已有用户名添加到过滤器
        }

// 5. 模拟用户注册时的查询逻辑
        {
            // 步骤1：先查询布隆过滤器
            if (usernameFilter.contains(newUsername)) {
                // 可能存在（有1%的误判概率）
                // 步骤2：二次确认（查询数据库）
                boolean isActuallyExists = database.query("SELECT COUNT(*) FROM users WHERE username = ?", newUsername);
                if (isActuallyExists) {
//                    return "用户名已存在";
                } else {
                    // 误判情况：实际不存在但过滤器误判存在
//                    return "用户名可用（误判后确认）";
                }
            } else {
                // 一定不存在（布隆过滤器的确定性）
                database.insert("INSERT INTO users (username) VALUES (?)", newUsername);
                usernameFilter.add(newUsername);  // 更新过滤器
//                return "注册成功";
            }
        }

// 6. 示例调用
        simulateRegistration("Alice123");  // 首次注册，成功
        simulateRegistration("Alice123");  // 二次注册，触发误判逻辑

    }
```

## Distributed counters 分布式计数器

** Id generator¶ Id 生成器**